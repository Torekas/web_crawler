{"schema_version": "case_v1", "case_id": "exp_20251216T210953Z_dcb546c6_case_00000", "experiment_id": "exp_20251216T210953Z_dcb546c6", "created_at": "2025-12-16T21:09:53.787584+00:00", "seed": 1337, "question": {"question_id": "synthetic_math_v1_1337_00000", "question": "A box holds 159 items. You have 137 identical boxes. How many items total?", "answer_key": "21783", "source": "synthetic_math_v1", "metadata": {"a": 159, "b": 137, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7855152447626205, "scores": {"correctness": 0.7868940559532756, "completeness": 0.7368940559532755, "reasoning_quality": 0.7568940559532755, "factuality": 0.9, "robustness": 0.7068940559532756}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"A box holds 159 items. You have 137 identical boxes. How many items total?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"A box holds 159 items. You have 137 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"A box holds 159 items. You have 137 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"A box holds 159 items. You have 137 identical boxes. How many items total?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7855152447626205, \"scores\": {\"correctness\": 0.7868940559532756, \"completeness\": 0.7368940559532755, \"reasoning_quality\": 0.7568940559532755, \"factuality\": 0.9, \"robustness\": 0.7068940559532756}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7855152447626205, "scores": {"correctness": 0.7868940559532756, "completeness": 0.7368940559532755, "reasoning_quality": 0.7568940559532755, "factuality": 0.9, "robustness": 0.7068940559532756}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7855152447626205, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 1, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
