{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00000", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.718152+00:00", "seed": 1337, "question": {"question_id": "synthetic_math_v1_1337_00000", "question": "A box holds 159 items. You have 137 identical boxes. How many items total?", "answer_key": "21783", "source": "synthetic_math_v1", "metadata": {"a": 159, "b": 137, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7903380922982033, "scores": {"correctness": 0.792922615372754, "completeness": 0.742922615372754, "reasoning_quality": 0.762922615372754, "factuality": 0.9, "robustness": 0.712922615372754}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"A box holds 159 items. You have 137 identical boxes. How many items total?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"A box holds 159 items. You have 137 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"A box holds 159 items. You have 137 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"A box holds 159 items. You have 137 identical boxes. How many items total?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7903380922982033, \"scores\": {\"correctness\": 0.792922615372754, \"completeness\": 0.742922615372754, \"reasoning_quality\": 0.762922615372754, \"factuality\": 0.9, \"robustness\": 0.712922615372754}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7903380922982033, "scores": {"correctness": 0.792922615372754, "completeness": 0.742922615372754, "reasoning_quality": 0.762922615372754, "factuality": 0.9, "robustness": 0.712922615372754}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7903380922982033, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00001", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.739409+00:00", "seed": 1338, "question": {"question_id": "synthetic_math_v1_1337_00001", "question": "What is 150 + 188?", "answer_key": "338", "source": "synthetic_math_v1", "metadata": {"a": 150, "b": 188, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7754329508361937, "scores": {"correctness": 0.774291188545242, "completeness": 0.724291188545242, "reasoning_quality": 0.744291188545242, "factuality": 0.9, "robustness": 0.6942911885452421}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 150 + 188?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 150 + 188?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 150 + 188?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 150 + 188?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7754329508361937, \"scores\": {\"correctness\": 0.774291188545242, \"completeness\": 0.724291188545242, \"reasoning_quality\": 0.744291188545242, \"factuality\": 0.9, \"robustness\": 0.6942911885452421}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7754329508361937, "scores": {"correctness": 0.774291188545242, "completeness": 0.724291188545242, "reasoning_quality": 0.744291188545242, "factuality": 0.9, "robustness": 0.6942911885452421}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7754329508361937, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00002", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.752934+00:00", "seed": 1339, "question": {"question_id": "synthetic_math_v1_1337_00002", "question": "What is 199 - 86?", "answer_key": "113", "source": "synthetic_math_v1", "metadata": {"a": 199, "b": 86, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7812281790106621, "scores": {"correctness": 0.7815352237633276, "completeness": 0.7315352237633276, "reasoning_quality": 0.7515352237633276, "factuality": 0.9, "robustness": 0.7015352237633277}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 199 - 86?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 199 - 86?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 199 - 86?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 199 - 86?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7812281790106621, \"scores\": {\"correctness\": 0.7815352237633276, \"completeness\": 0.7315352237633276, \"reasoning_quality\": 0.7515352237633276, \"factuality\": 0.9, \"robustness\": 0.7015352237633277}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7812281790106621, "scores": {"correctness": 0.7815352237633276, "completeness": 0.7315352237633276, "reasoning_quality": 0.7515352237633276, "factuality": 0.9, "robustness": 0.7015352237633277}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7812281790106621, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00003", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.764598+00:00", "seed": 1340, "question": {"question_id": "synthetic_math_v1_1337_00003", "question": "What is 163 - 93?", "answer_key": "70", "source": "synthetic_math_v1", "metadata": {"a": 163, "b": 93, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7985139141033181, "scores": {"correctness": 0.8031423926291476, "completeness": 0.7531423926291475, "reasoning_quality": 0.7731423926291475, "factuality": 0.9, "robustness": 0.7231423926291476}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 163 - 93?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 163 - 93?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 163 - 93?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 163 - 93?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7985139141033181, \"scores\": {\"correctness\": 0.8031423926291476, \"completeness\": 0.7531423926291475, \"reasoning_quality\": 0.7731423926291475, \"factuality\": 0.9, \"robustness\": 0.7231423926291476}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7985139141033181, "scores": {"correctness": 0.8031423926291476, "completeness": 0.7531423926291475, "reasoning_quality": 0.7731423926291475, "factuality": 0.9, "robustness": 0.7231423926291476}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7985139141033181, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00004", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.774600+00:00", "seed": 1341, "question": {"question_id": "synthetic_math_v1_1337_00004", "question": "What is 101 + 179?", "answer_key": "280", "source": "synthetic_math_v1", "metadata": {"a": 101, "b": 179, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7611398077232957, "scores": {"correctness": 0.7564247596541196, "completeness": 0.7064247596541195, "reasoning_quality": 0.7264247596541196, "factuality": 0.9, "robustness": 0.6764247596541196}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 101 + 179?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 101 + 179?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 101 + 179?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 101 + 179?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7611398077232957, \"scores\": {\"correctness\": 0.7564247596541196, \"completeness\": 0.7064247596541195, \"reasoning_quality\": 0.7264247596541196, \"factuality\": 0.9, \"robustness\": 0.6764247596541196}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7611398077232957, "scores": {"correctness": 0.7564247596541196, "completeness": 0.7064247596541195, "reasoning_quality": 0.7264247596541196, "factuality": 0.9, "robustness": 0.6764247596541196}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7611398077232957, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00005", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.785495+00:00", "seed": 1342, "question": {"question_id": "synthetic_math_v1_1337_00005", "question": "What is 195 - 169?", "answer_key": "26", "source": "synthetic_math_v1", "metadata": {"a": 195, "b": 169, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7900577910145281, "scores": {"correctness": 0.7925722387681602, "completeness": 0.7425722387681601, "reasoning_quality": 0.7625722387681602, "factuality": 0.9, "robustness": 0.7125722387681602}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 195 - 169?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 195 - 169?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 195 - 169?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 195 - 169?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7900577910145281, \"scores\": {\"correctness\": 0.7925722387681602, \"completeness\": 0.7425722387681601, \"reasoning_quality\": 0.7625722387681602, \"factuality\": 0.9, \"robustness\": 0.7125722387681602}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7900577910145281, "scores": {"correctness": 0.7925722387681602, "completeness": 0.7425722387681601, "reasoning_quality": 0.7625722387681602, "factuality": 0.9, "robustness": 0.7125722387681602}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7900577910145281, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00006", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.820856+00:00", "seed": 1343, "question": {"question_id": "synthetic_math_v1_1337_00006", "question": "A box holds 28 items. You have 109 identical boxes. How many items total?", "answer_key": "3052", "source": "synthetic_math_v1", "metadata": {"a": 28, "b": 109, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7834984212335514, "scores": {"correctness": 0.7843730265419393, "completeness": 0.7343730265419393, "reasoning_quality": 0.7543730265419393, "factuality": 0.9, "robustness": 0.7043730265419393}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"A box holds 28 items. You have 109 identical boxes. How many items total?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"A box holds 28 items. You have 109 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"A box holds 28 items. You have 109 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"A box holds 28 items. You have 109 identical boxes. How many items total?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7834984212335514, \"scores\": {\"correctness\": 0.7843730265419393, \"completeness\": 0.7343730265419393, \"reasoning_quality\": 0.7543730265419393, \"factuality\": 0.9, \"robustness\": 0.7043730265419393}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7834984212335514, "scores": {"correctness": 0.7843730265419393, "completeness": 0.7343730265419393, "reasoning_quality": 0.7543730265419393, "factuality": 0.9, "robustness": 0.7043730265419393}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7834984212335514, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00007", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.852599+00:00", "seed": 1344, "question": {"question_id": "synthetic_math_v1_1337_00007", "question": "What is 17 * 130?", "answer_key": "2210", "source": "synthetic_math_v1", "metadata": {"a": 17, "b": 130, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7874707916545877, "scores": {"correctness": 0.7893384895682346, "completeness": 0.7393384895682346, "reasoning_quality": 0.7593384895682346, "factuality": 0.9, "robustness": 0.7093384895682346}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 17 * 130?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 17 * 130?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 17 * 130?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 17 * 130?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7874707916545877, \"scores\": {\"correctness\": 0.7893384895682346, \"completeness\": 0.7393384895682346, \"reasoning_quality\": 0.7593384895682346, \"factuality\": 0.9, \"robustness\": 0.7093384895682346}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7874707916545877, "scores": {"correctness": 0.7893384895682346, "completeness": 0.7393384895682346, "reasoning_quality": 0.7593384895682346, "factuality": 0.9, "robustness": 0.7093384895682346}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7874707916545877, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00008", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.866600+00:00", "seed": 1345, "question": {"question_id": "synthetic_math_v1_1337_00008", "question": "What is 104 * 104?", "answer_key": "10816", "source": "synthetic_math_v1", "metadata": {"a": 104, "b": 104, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7785601639342057, "scores": {"correctness": 0.7782002049177571, "completeness": 0.728200204917757, "reasoning_quality": 0.7482002049177571, "factuality": 0.9, "robustness": 0.6982002049177571}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 104 * 104?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 104 * 104?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 104 * 104?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 104 * 104?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7785601639342057, \"scores\": {\"correctness\": 0.7782002049177571, \"completeness\": 0.728200204917757, \"reasoning_quality\": 0.7482002049177571, \"factuality\": 0.9, \"robustness\": 0.6982002049177571}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7785601639342057, "scores": {"correctness": 0.7782002049177571, "completeness": 0.728200204917757, "reasoning_quality": 0.7482002049177571, "factuality": 0.9, "robustness": 0.6982002049177571}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7785601639342057, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00009", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.878331+00:00", "seed": 1346, "question": {"question_id": "synthetic_math_v1_1337_00009", "question": "What is 170 - 5?", "answer_key": "165", "source": "synthetic_math_v1", "metadata": {"a": 170, "b": 5, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7798296920339066, "scores": {"correctness": 0.7797871150423832, "completeness": 0.7297871150423831, "reasoning_quality": 0.7497871150423832, "factuality": 0.9, "robustness": 0.6997871150423832}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 170 - 5?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 170 - 5?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 170 - 5?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 170 - 5?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7798296920339066, \"scores\": {\"correctness\": 0.7797871150423832, \"completeness\": 0.7297871150423831, \"reasoning_quality\": 0.7497871150423832, \"factuality\": 0.9, \"robustness\": 0.6997871150423832}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7798296920339066, "scores": {"correctness": 0.7797871150423832, "completeness": 0.7297871150423831, "reasoning_quality": 0.7497871150423832, "factuality": 0.9, "robustness": 0.6997871150423832}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7798296920339066, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00010", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.897065+00:00", "seed": 1347, "question": {"question_id": "synthetic_math_v1_1337_00010", "question": "What is 153 - 31?", "answer_key": "122", "source": "synthetic_math_v1", "metadata": {"a": 153, "b": 31, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7962519312768104, "scores": {"correctness": 0.8003149140960129, "completeness": 0.7503149140960128, "reasoning_quality": 0.7703149140960128, "factuality": 0.9, "robustness": 0.7203149140960129}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 153 - 31?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 153 - 31?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 153 - 31?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 153 - 31?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7962519312768104, \"scores\": {\"correctness\": 0.8003149140960129, \"completeness\": 0.7503149140960128, \"reasoning_quality\": 0.7703149140960128, \"factuality\": 0.9, \"robustness\": 0.7203149140960129}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7962519312768104, "scores": {"correctness": 0.8003149140960129, "completeness": 0.7503149140960128, "reasoning_quality": 0.7703149140960128, "factuality": 0.9, "robustness": 0.7203149140960129}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7962519312768104, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00011", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.913190+00:00", "seed": 1348, "question": {"question_id": "synthetic_math_v1_1337_00011", "question": "What is 64 - 44?", "answer_key": "20", "source": "synthetic_math_v1", "metadata": {"a": 64, "b": 44, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7641664583017026, "scores": {"correctness": 0.7602080728771282, "completeness": 0.7102080728771282, "reasoning_quality": 0.7302080728771282, "factuality": 0.9, "robustness": 0.6802080728771283}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 64 - 44?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 64 - 44?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 64 - 44?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 64 - 44?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7641664583017026, \"scores\": {\"correctness\": 0.7602080728771282, \"completeness\": 0.7102080728771282, \"reasoning_quality\": 0.7302080728771282, \"factuality\": 0.9, \"robustness\": 0.6802080728771283}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7641664583017026, "scores": {"correctness": 0.7602080728771282, "completeness": 0.7102080728771282, "reasoning_quality": 0.7302080728771282, "factuality": 0.9, "robustness": 0.6802080728771283}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7641664583017026, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00012", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.926193+00:00", "seed": 1349, "question": {"question_id": "synthetic_math_v1_1337_00012", "question": "What is 174 * 177?", "answer_key": "30798", "source": "synthetic_math_v1", "metadata": {"a": 174, "b": 177, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7892740892397158, "scores": {"correctness": 0.7915926115496447, "completeness": 0.7415926115496446, "reasoning_quality": 0.7615926115496446, "factuality": 0.9, "robustness": 0.7115926115496447}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 174 * 177?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 174 * 177?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 174 * 177?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 174 * 177?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7892740892397158, \"scores\": {\"correctness\": 0.7915926115496447, \"completeness\": 0.7415926115496446, \"reasoning_quality\": 0.7615926115496446, \"factuality\": 0.9, \"robustness\": 0.7115926115496447}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7892740892397158, "scores": {"correctness": 0.7915926115496447, "completeness": 0.7415926115496446, "reasoning_quality": 0.7615926115496446, "factuality": 0.9, "robustness": 0.7115926115496447}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7892740892397158, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00013", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.940186+00:00", "seed": 1350, "question": {"question_id": "synthetic_math_v1_1337_00013", "question": "A box holds 68 items. You have 52 identical boxes. How many items total?", "answer_key": "3536", "source": "synthetic_math_v1", "metadata": {"a": 68, "b": 52, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.775844208843624, "scores": {"correctness": 0.7748052610545301, "completeness": 0.72480526105453, "reasoning_quality": 0.74480526105453, "factuality": 0.9, "robustness": 0.6948052610545301}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"A box holds 68 items. You have 52 identical boxes. How many items total?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"A box holds 68 items. You have 52 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"A box holds 68 items. You have 52 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"A box holds 68 items. You have 52 identical boxes. How many items total?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.775844208843624, \"scores\": {\"correctness\": 0.7748052610545301, \"completeness\": 0.72480526105453, \"reasoning_quality\": 0.74480526105453, \"factuality\": 0.9, \"robustness\": 0.6948052610545301}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.775844208843624, "scores": {"correctness": 0.7748052610545301, "completeness": 0.72480526105453, "reasoning_quality": 0.74480526105453, "factuality": 0.9, "robustness": 0.6948052610545301}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.775844208843624, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00014", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.952491+00:00", "seed": 1351, "question": {"question_id": "synthetic_math_v1_1337_00014", "question": "What is 135 * 159?", "answer_key": "21465", "source": "synthetic_math_v1", "metadata": {"a": 135, "b": 159, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7897778174817681, "scores": {"correctness": 0.7922222718522101, "completeness": 0.74222227185221, "reasoning_quality": 0.76222227185221, "factuality": 0.9, "robustness": 0.7122222718522101}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 135 * 159?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 135 * 159?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 135 * 159?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 135 * 159?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7897778174817681, \"scores\": {\"correctness\": 0.7922222718522101, \"completeness\": 0.74222227185221, \"reasoning_quality\": 0.76222227185221, \"factuality\": 0.9, \"robustness\": 0.7122222718522101}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7897778174817681, "scores": {"correctness": 0.7922222718522101, "completeness": 0.74222227185221, "reasoning_quality": 0.76222227185221, "factuality": 0.9, "robustness": 0.7122222718522101}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7897778174817681, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00015", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.970908+00:00", "seed": 1352, "question": {"question_id": "synthetic_math_v1_1337_00015", "question": "What is 19 * 105?", "answer_key": "1995", "source": "synthetic_math_v1", "metadata": {"a": 19, "b": 105, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7925745317612859, "scores": {"correctness": 0.7957181647016073, "completeness": 0.7457181647016072, "reasoning_quality": 0.7657181647016073, "factuality": 0.9, "robustness": 0.7157181647016073}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 19 * 105?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 19 * 105?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 19 * 105?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 19 * 105?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7925745317612859, \"scores\": {\"correctness\": 0.7957181647016073, \"completeness\": 0.7457181647016072, \"reasoning_quality\": 0.7657181647016073, \"factuality\": 0.9, \"robustness\": 0.7157181647016073}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7925745317612859, "scores": {"correctness": 0.7957181647016073, "completeness": 0.7457181647016072, "reasoning_quality": 0.7657181647016073, "factuality": 0.9, "robustness": 0.7157181647016073}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7925745317612859, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00016", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:31.987723+00:00", "seed": 1353, "question": {"question_id": "synthetic_math_v1_1337_00016", "question": "What is 14 + 173?", "answer_key": "187", "source": "synthetic_math_v1", "metadata": {"a": 14, "b": 173, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7763497728674768, "scores": {"correctness": 0.7754372160843459, "completeness": 0.7254372160843459, "reasoning_quality": 0.7454372160843459, "factuality": 0.9, "robustness": 0.6954372160843459}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 14 + 173?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 14 + 173?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 14 + 173?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 14 + 173?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7763497728674768, \"scores\": {\"correctness\": 0.7754372160843459, \"completeness\": 0.7254372160843459, \"reasoning_quality\": 0.7454372160843459, \"factuality\": 0.9, \"robustness\": 0.6954372160843459}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7763497728674768, "scores": {"correctness": 0.7754372160843459, "completeness": 0.7254372160843459, "reasoning_quality": 0.7454372160843459, "factuality": 0.9, "robustness": 0.6954372160843459}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7763497728674768, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00017", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.000272+00:00", "seed": 1354, "question": {"question_id": "synthetic_math_v1_1337_00017", "question": "What is 163 + 51?", "answer_key": "214", "source": "synthetic_math_v1", "metadata": {"a": 163, "b": 51, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7953735560188658, "scores": {"correctness": 0.7992169450235822, "completeness": 0.7492169450235822, "reasoning_quality": 0.7692169450235822, "factuality": 0.9, "robustness": 0.7192169450235822}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 163 + 51?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 163 + 51?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 163 + 51?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 163 + 51?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7953735560188658, \"scores\": {\"correctness\": 0.7992169450235822, \"completeness\": 0.7492169450235822, \"reasoning_quality\": 0.7692169450235822, \"factuality\": 0.9, \"robustness\": 0.7192169450235822}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7953735560188658, "scores": {"correctness": 0.7992169450235822, "completeness": 0.7492169450235822, "reasoning_quality": 0.7692169450235822, "factuality": 0.9, "robustness": 0.7192169450235822}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7953735560188658, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00018", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.012645+00:00", "seed": 1355, "question": {"question_id": "synthetic_math_v1_1337_00018", "question": "What is 27 + 73?", "answer_key": "100", "source": "synthetic_math_v1", "metadata": {"a": 27, "b": 73, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7992820410927398, "scores": {"correctness": 0.8041025513659247, "completeness": 0.7541025513659246, "reasoning_quality": 0.7741025513659247, "factuality": 0.9, "robustness": 0.7241025513659247}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 27 + 73?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 27 + 73?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 27 + 73?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 27 + 73?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7992820410927398, \"scores\": {\"correctness\": 0.8041025513659247, \"completeness\": 0.7541025513659246, \"reasoning_quality\": 0.7741025513659247, \"factuality\": 0.9, \"robustness\": 0.7241025513659247}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7992820410927398, "scores": {"correctness": 0.8041025513659247, "completeness": 0.7541025513659246, "reasoning_quality": 0.7741025513659247, "factuality": 0.9, "robustness": 0.7241025513659247}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7992820410927398, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00019", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.030143+00:00", "seed": 1356, "question": {"question_id": "synthetic_math_v1_1337_00019", "question": "A box holds 116 items. You have 192 identical boxes. How many items total?", "answer_key": "22272", "source": "synthetic_math_v1", "metadata": {"a": 116, "b": 192, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7715529007249036, "scores": {"correctness": 0.7694411259061295, "completeness": 0.7194411259061294, "reasoning_quality": 0.7394411259061294, "factuality": 0.9, "robustness": 0.6894411259061295}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"A box holds 116 items. You have 192 identical boxes. How many items total?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"A box holds 116 items. You have 192 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"A box holds 116 items. You have 192 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"A box holds 116 items. You have 192 identical boxes. How many items total?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7715529007249036, \"scores\": {\"correctness\": 0.7694411259061295, \"completeness\": 0.7194411259061294, \"reasoning_quality\": 0.7394411259061294, \"factuality\": 0.9, \"robustness\": 0.6894411259061295}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7715529007249036, "scores": {"correctness": 0.7694411259061295, "completeness": 0.7194411259061294, "reasoning_quality": 0.7394411259061294, "factuality": 0.9, "robustness": 0.6894411259061295}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7715529007249036, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00020", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.046530+00:00", "seed": 1357, "question": {"question_id": "synthetic_math_v1_1337_00020", "question": "What is 157 - 86?", "answer_key": "71", "source": "synthetic_math_v1", "metadata": {"a": 157, "b": 86, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7633721378485125, "scores": {"correctness": 0.7592151723106406, "completeness": 0.7092151723106406, "reasoning_quality": 0.7292151723106406, "factuality": 0.9, "robustness": 0.6792151723106407}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 157 - 86?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 157 - 86?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 157 - 86?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 157 - 86?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7633721378485125, \"scores\": {\"correctness\": 0.7592151723106406, \"completeness\": 0.7092151723106406, \"reasoning_quality\": 0.7292151723106406, \"factuality\": 0.9, \"robustness\": 0.6792151723106407}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7633721378485125, "scores": {"correctness": 0.7592151723106406, "completeness": 0.7092151723106406, "reasoning_quality": 0.7292151723106406, "factuality": 0.9, "robustness": 0.6792151723106407}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7633721378485125, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00021", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.059575+00:00", "seed": 1358, "question": {"question_id": "synthetic_math_v1_1337_00021", "question": "A box holds 147 items. You have 59 identical boxes. How many items total?", "answer_key": "8673", "source": "synthetic_math_v1", "metadata": {"a": 147, "b": 59, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7654120225944548, "scores": {"correctness": 0.7617650282430685, "completeness": 0.7117650282430684, "reasoning_quality": 0.7317650282430684, "factuality": 0.9, "robustness": 0.6817650282430685}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"A box holds 147 items. You have 59 identical boxes. How many items total?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"A box holds 147 items. You have 59 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"A box holds 147 items. You have 59 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"A box holds 147 items. You have 59 identical boxes. How many items total?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7654120225944548, \"scores\": {\"correctness\": 0.7617650282430685, \"completeness\": 0.7117650282430684, \"reasoning_quality\": 0.7317650282430684, \"factuality\": 0.9, \"robustness\": 0.6817650282430685}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7654120225944548, "scores": {"correctness": 0.7617650282430685, "completeness": 0.7117650282430684, "reasoning_quality": 0.7317650282430684, "factuality": 0.9, "robustness": 0.6817650282430685}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7654120225944548, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00022", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.073596+00:00", "seed": 1359, "question": {"question_id": "synthetic_math_v1_1337_00022", "question": "A box holds 143 items. You have 186 identical boxes. How many items total?", "answer_key": "26598", "source": "synthetic_math_v1", "metadata": {"a": 143, "b": 186, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7785744933059588, "scores": {"correctness": 0.7782181166324486, "completeness": 0.7282181166324485, "reasoning_quality": 0.7482181166324485, "factuality": 0.9, "robustness": 0.6982181166324486}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"A box holds 143 items. You have 186 identical boxes. How many items total?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"A box holds 143 items. You have 186 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"A box holds 143 items. You have 186 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"A box holds 143 items. You have 186 identical boxes. How many items total?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7785744933059588, \"scores\": {\"correctness\": 0.7782181166324486, \"completeness\": 0.7282181166324485, \"reasoning_quality\": 0.7482181166324485, \"factuality\": 0.9, \"robustness\": 0.6982181166324486}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7785744933059588, "scores": {"correctness": 0.7782181166324486, "completeness": 0.7282181166324485, "reasoning_quality": 0.7482181166324485, "factuality": 0.9, "robustness": 0.6982181166324486}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7785744933059588, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00023", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.086655+00:00", "seed": 1360, "question": {"question_id": "synthetic_math_v1_1337_00023", "question": "What is 55 + 157?", "answer_key": "212", "source": "synthetic_math_v1", "metadata": {"a": 55, "b": 157, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7785568339869353, "scores": {"correctness": 0.7781960424836691, "completeness": 0.7281960424836691, "reasoning_quality": 0.7481960424836691, "factuality": 0.9, "robustness": 0.6981960424836692}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 55 + 157?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 55 + 157?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 55 + 157?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 55 + 157?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7785568339869353, \"scores\": {\"correctness\": 0.7781960424836691, \"completeness\": 0.7281960424836691, \"reasoning_quality\": 0.7481960424836691, \"factuality\": 0.9, \"robustness\": 0.6981960424836692}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7785568339869353, "scores": {"correctness": 0.7781960424836691, "completeness": 0.7281960424836691, "reasoning_quality": 0.7481960424836691, "factuality": 0.9, "robustness": 0.6981960424836692}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7785568339869353, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00024", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.106336+00:00", "seed": 1361, "question": {"question_id": "synthetic_math_v1_1337_00024", "question": "A box holds 136 items. You have 135 identical boxes. How many items total?", "answer_key": "18360", "source": "synthetic_math_v1", "metadata": {"a": 136, "b": 135, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7937170442832348, "scores": {"correctness": 0.7971463053540434, "completeness": 0.7471463053540434, "reasoning_quality": 0.7671463053540434, "factuality": 0.9, "robustness": 0.7171463053540434}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"A box holds 136 items. You have 135 identical boxes. How many items total?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"A box holds 136 items. You have 135 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"A box holds 136 items. You have 135 identical boxes. How many items total?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"A box holds 136 items. You have 135 identical boxes. How many items total?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7937170442832348, \"scores\": {\"correctness\": 0.7971463053540434, \"completeness\": 0.7471463053540434, \"reasoning_quality\": 0.7671463053540434, \"factuality\": 0.9, \"robustness\": 0.7171463053540434}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7937170442832348, "scores": {"correctness": 0.7971463053540434, "completeness": 0.7471463053540434, "reasoning_quality": 0.7671463053540434, "factuality": 0.9, "robustness": 0.7171463053540434}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7937170442832348, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00025", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.120689+00:00", "seed": 1362, "question": {"question_id": "synthetic_math_v1_1337_00025", "question": "What is 170 * 13?", "answer_key": "2210", "source": "synthetic_math_v1", "metadata": {"a": 170, "b": 13, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7909690343419664, "scores": {"correctness": 0.793711292927458, "completeness": 0.743711292927458, "reasoning_quality": 0.763711292927458, "factuality": 0.9, "robustness": 0.713711292927458}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 170 * 13?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 170 * 13?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 170 * 13?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 170 * 13?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7909690343419664, \"scores\": {\"correctness\": 0.793711292927458, \"completeness\": 0.743711292927458, \"reasoning_quality\": 0.763711292927458, \"factuality\": 0.9, \"robustness\": 0.713711292927458}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7909690343419664, "scores": {"correctness": 0.793711292927458, "completeness": 0.743711292927458, "reasoning_quality": 0.763711292927458, "factuality": 0.9, "robustness": 0.713711292927458}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7909690343419664, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00026", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.133688+00:00", "seed": 1363, "question": {"question_id": "synthetic_math_v1_1337_00026", "question": "What is 189 - 150?", "answer_key": "39", "source": "synthetic_math_v1", "metadata": {"a": 189, "b": 150, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7852345643321572, "scores": {"correctness": 0.7865432054151964, "completeness": 0.7365432054151964, "reasoning_quality": 0.7565432054151964, "factuality": 0.9, "robustness": 0.7065432054151964}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 189 - 150?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 189 - 150?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 189 - 150?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 189 - 150?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7852345643321572, \"scores\": {\"correctness\": 0.7865432054151964, \"completeness\": 0.7365432054151964, \"reasoning_quality\": 0.7565432054151964, \"factuality\": 0.9, \"robustness\": 0.7065432054151964}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7852345643321572, "scores": {"correctness": 0.7865432054151964, "completeness": 0.7365432054151964, "reasoning_quality": 0.7565432054151964, "factuality": 0.9, "robustness": 0.7065432054151964}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7852345643321572, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00027", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.145731+00:00", "seed": 1364, "question": {"question_id": "synthetic_math_v1_1337_00027", "question": "What is 7 - 134?", "answer_key": "-127", "source": "synthetic_math_v1", "metadata": {"a": 7, "b": 134, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7816824167882519, "scores": {"correctness": 0.7821030209853147, "completeness": 0.7321030209853147, "reasoning_quality": 0.7521030209853147, "factuality": 0.9, "robustness": 0.7021030209853147}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 7 - 134?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 7 - 134?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 7 - 134?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 7 - 134?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7816824167882519, \"scores\": {\"correctness\": 0.7821030209853147, \"completeness\": 0.7321030209853147, \"reasoning_quality\": 0.7521030209853147, \"factuality\": 0.9, \"robustness\": 0.7021030209853147}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7816824167882519, "scores": {"correctness": 0.7821030209853147, "completeness": 0.7321030209853147, "reasoning_quality": 0.7521030209853147, "factuality": 0.9, "robustness": 0.7021030209853147}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7816824167882519, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00028", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.161981+00:00", "seed": 1365, "question": {"question_id": "synthetic_math_v1_1337_00028", "question": "What is 139 * 193?", "answer_key": "26827", "source": "synthetic_math_v1", "metadata": {"a": 139, "b": 193, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7956127891085377, "scores": {"correctness": 0.7995159863856721, "completeness": 0.7495159863856721, "reasoning_quality": 0.7695159863856721, "factuality": 0.9, "robustness": 0.7195159863856722}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 139 * 193?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 139 * 193?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 139 * 193?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 139 * 193?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7956127891085377, \"scores\": {\"correctness\": 0.7995159863856721, \"completeness\": 0.7495159863856721, \"reasoning_quality\": 0.7695159863856721, \"factuality\": 0.9, \"robustness\": 0.7195159863856722}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7956127891085377, "scores": {"correctness": 0.7995159863856721, "completeness": 0.7495159863856721, "reasoning_quality": 0.7695159863856721, "factuality": 0.9, "robustness": 0.7195159863856722}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7956127891085377, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00029", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.178616+00:00", "seed": 1366, "question": {"question_id": "synthetic_math_v1_1337_00029", "question": "What is 91 * 189?", "answer_key": "17199", "source": "synthetic_math_v1", "metadata": {"a": 91, "b": 189, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7987507116876756, "scores": {"correctness": 0.8034383896095945, "completeness": 0.7534383896095944, "reasoning_quality": 0.7734383896095944, "factuality": 0.9, "robustness": 0.7234383896095945}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 91 * 189?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 91 * 189?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 91 * 189?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 91 * 189?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7987507116876756, \"scores\": {\"correctness\": 0.8034383896095945, \"completeness\": 0.7534383896095944, \"reasoning_quality\": 0.7734383896095944, \"factuality\": 0.9, \"robustness\": 0.7234383896095945}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7987507116876756, "scores": {"correctness": 0.8034383896095945, "completeness": 0.7534383896095944, "reasoning_quality": 0.7734383896095944, "factuality": 0.9, "robustness": 0.7234383896095945}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7987507116876756, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00030", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.190620+00:00", "seed": 1367, "question": {"question_id": "synthetic_math_v1_1337_00030", "question": "What is 166 - 66?", "answer_key": "100", "source": "synthetic_math_v1", "metadata": {"a": 166, "b": 66, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7941243273706169, "scores": {"correctness": 0.797655409213271, "completeness": 0.747655409213271, "reasoning_quality": 0.767655409213271, "factuality": 0.9, "robustness": 0.7176554092132711}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 166 - 66?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 166 - 66?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 166 - 66?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 166 - 66?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7941243273706169, \"scores\": {\"correctness\": 0.797655409213271, \"completeness\": 0.747655409213271, \"reasoning_quality\": 0.767655409213271, \"factuality\": 0.9, \"robustness\": 0.7176554092132711}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7941243273706169, "scores": {"correctness": 0.797655409213271, "completeness": 0.747655409213271, "reasoning_quality": 0.767655409213271, "factuality": 0.9, "robustness": 0.7176554092132711}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7941243273706169, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00031", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.203140+00:00", "seed": 1368, "question": {"question_id": "synthetic_math_v1_1337_00031", "question": "What is 18 + 182?", "answer_key": "200", "source": "synthetic_math_v1", "metadata": {"a": 18, "b": 182, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7876011554258524, "scores": {"correctness": 0.7895014442823154, "completeness": 0.7395014442823153, "reasoning_quality": 0.7595014442823154, "factuality": 0.9, "robustness": 0.7095014442823154}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 18 + 182?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 18 + 182?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 18 + 182?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 18 + 182?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7876011554258524, \"scores\": {\"correctness\": 0.7895014442823154, \"completeness\": 0.7395014442823153, \"reasoning_quality\": 0.7595014442823154, \"factuality\": 0.9, \"robustness\": 0.7095014442823154}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7876011554258524, "scores": {"correctness": 0.7895014442823154, "completeness": 0.7395014442823153, "reasoning_quality": 0.7595014442823154, "factuality": 0.9, "robustness": 0.7095014442823154}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7876011554258524, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00032", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.216097+00:00", "seed": 1369, "question": {"question_id": "synthetic_math_v1_1337_00032", "question": "What is 16 - 44?", "answer_key": "-28", "source": "synthetic_math_v1", "metadata": {"a": 16, "b": 44, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7732019719505783, "scores": {"correctness": 0.7715024649382228, "completeness": 0.7215024649382228, "reasoning_quality": 0.7415024649382228, "factuality": 0.9, "robustness": 0.6915024649382229}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 16 - 44?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 16 - 44?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 16 - 44?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 16 - 44?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7732019719505783, \"scores\": {\"correctness\": 0.7715024649382228, \"completeness\": 0.7215024649382228, \"reasoning_quality\": 0.7415024649382228, \"factuality\": 0.9, \"robustness\": 0.6915024649382229}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7732019719505783, "scores": {"correctness": 0.7715024649382228, "completeness": 0.7215024649382228, "reasoning_quality": 0.7415024649382228, "factuality": 0.9, "robustness": 0.6915024649382229}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7732019719505783, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00033", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.234932+00:00", "seed": 1370, "question": {"question_id": "synthetic_math_v1_1337_00033", "question": "What is 21 - 50?", "answer_key": "-29", "source": "synthetic_math_v1", "metadata": {"a": 21, "b": 50, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7888593176424694, "scores": {"correctness": 0.7910741470530867, "completeness": 0.7410741470530866, "reasoning_quality": 0.7610741470530866, "factuality": 0.9, "robustness": 0.7110741470530867}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 21 - 50?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 21 - 50?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 21 - 50?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 21 - 50?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7888593176424694, \"scores\": {\"correctness\": 0.7910741470530867, \"completeness\": 0.7410741470530866, \"reasoning_quality\": 0.7610741470530866, \"factuality\": 0.9, \"robustness\": 0.7110741470530867}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7888593176424694, "scores": {"correctness": 0.7910741470530867, "completeness": 0.7410741470530866, "reasoning_quality": 0.7610741470530866, "factuality": 0.9, "robustness": 0.7110741470530867}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7888593176424694, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00034", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.249169+00:00", "seed": 1371, "question": {"question_id": "synthetic_math_v1_1337_00034", "question": "What is 139 + 65?", "answer_key": "204", "source": "synthetic_math_v1", "metadata": {"a": 139, "b": 65, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7829996367929963, "scores": {"correctness": 0.7837495459912454, "completeness": 0.7337495459912453, "reasoning_quality": 0.7537495459912453, "factuality": 0.9, "robustness": 0.7037495459912454}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 139 + 65?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 139 + 65?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 139 + 65?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 139 + 65?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7829996367929963, \"scores\": {\"correctness\": 0.7837495459912454, \"completeness\": 0.7337495459912453, \"reasoning_quality\": 0.7537495459912453, \"factuality\": 0.9, \"robustness\": 0.7037495459912454}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7829996367929963, "scores": {"correctness": 0.7837495459912454, "completeness": 0.7337495459912453, "reasoning_quality": 0.7537495459912453, "factuality": 0.9, "robustness": 0.7037495459912454}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7829996367929963, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00035", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.263172+00:00", "seed": 1372, "question": {"question_id": "synthetic_math_v1_1337_00035", "question": "What is 142 - 39?", "answer_key": "103", "source": "synthetic_math_v1", "metadata": {"a": 142, "b": 39, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7748997088819294, "scores": {"correctness": 0.7736246361024117, "completeness": 0.7236246361024117, "reasoning_quality": 0.7436246361024117, "factuality": 0.9, "robustness": 0.6936246361024118}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 142 - 39?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 142 - 39?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 142 - 39?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 142 - 39?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7748997088819294, \"scores\": {\"correctness\": 0.7736246361024117, \"completeness\": 0.7236246361024117, \"reasoning_quality\": 0.7436246361024117, \"factuality\": 0.9, \"robustness\": 0.6936246361024118}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7748997088819294, "scores": {"correctness": 0.7736246361024117, "completeness": 0.7236246361024117, "reasoning_quality": 0.7436246361024117, "factuality": 0.9, "robustness": 0.6936246361024118}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7748997088819294, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00036", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.277170+00:00", "seed": 1373, "question": {"question_id": "synthetic_math_v1_1337_00036", "question": "What is 90 * 156?", "answer_key": "14040", "source": "synthetic_math_v1", "metadata": {"a": 90, "b": 156, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7962854235209043, "scores": {"correctness": 0.8003567794011303, "completeness": 0.7503567794011302, "reasoning_quality": 0.7703567794011302, "factuality": 0.9, "robustness": 0.7203567794011303}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 90 * 156?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 90 * 156?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 90 * 156?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 90 * 156?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7962854235209043, \"scores\": {\"correctness\": 0.8003567794011303, \"completeness\": 0.7503567794011302, \"reasoning_quality\": 0.7703567794011302, \"factuality\": 0.9, \"robustness\": 0.7203567794011303}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7962854235209043, "scores": {"correctness": 0.8003567794011303, "completeness": 0.7503567794011302, "reasoning_quality": 0.7703567794011302, "factuality": 0.9, "robustness": 0.7203567794011303}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7962854235209043, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00037", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.299698+00:00", "seed": 1374, "question": {"question_id": "synthetic_math_v1_1337_00037", "question": "What is 11 - 111?", "answer_key": "-100", "source": "synthetic_math_v1", "metadata": {"a": 11, "b": 111, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7725105683694623, "scores": {"correctness": 0.7706382104618278, "completeness": 0.7206382104618277, "reasoning_quality": 0.7406382104618278, "factuality": 0.9, "robustness": 0.6906382104618278}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 11 - 111?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 11 - 111?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 11 - 111?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 11 - 111?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7725105683694623, \"scores\": {\"correctness\": 0.7706382104618278, \"completeness\": 0.7206382104618277, \"reasoning_quality\": 0.7406382104618278, \"factuality\": 0.9, \"robustness\": 0.6906382104618278}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7725105683694623, "scores": {"correctness": 0.7706382104618278, "completeness": 0.7206382104618277, "reasoning_quality": 0.7406382104618278, "factuality": 0.9, "robustness": 0.6906382104618278}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7725105683694623, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00038", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.316667+00:00", "seed": 1375, "question": {"question_id": "synthetic_math_v1_1337_00038", "question": "What is 190 + 40?", "answer_key": "230", "source": "synthetic_math_v1", "metadata": {"a": 190, "b": 40, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7704207665202261, "scores": {"correctness": 0.7680259581502825, "completeness": 0.7180259581502825, "reasoning_quality": 0.7380259581502825, "factuality": 0.9, "robustness": 0.6880259581502826}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 190 + 40?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 190 + 40?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 190 + 40?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 190 + 40?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7704207665202261, \"scores\": {\"correctness\": 0.7680259581502825, \"completeness\": 0.7180259581502825, \"reasoning_quality\": 0.7380259581502825, \"factuality\": 0.9, \"robustness\": 0.6880259581502826}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7704207665202261, "scores": {"correctness": 0.7680259581502825, "completeness": 0.7180259581502825, "reasoning_quality": 0.7380259581502825, "factuality": 0.9, "robustness": 0.6880259581502826}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7704207665202261, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00039", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.337734+00:00", "seed": 1376, "question": {"question_id": "synthetic_math_v1_1337_00039", "question": "What is 163 - 119?", "answer_key": "44", "source": "synthetic_math_v1", "metadata": {"a": 163, "b": 119, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7899402625697987, "scores": {"correctness": 0.7924253282122482, "completeness": 0.7424253282122482, "reasoning_quality": 0.7624253282122482, "factuality": 0.9, "robustness": 0.7124253282122482}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 163 - 119?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 163 - 119?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 163 - 119?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 163 - 119?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7899402625697987, \"scores\": {\"correctness\": 0.7924253282122482, \"completeness\": 0.7424253282122482, \"reasoning_quality\": 0.7624253282122482, \"factuality\": 0.9, \"robustness\": 0.7124253282122482}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7899402625697987, "scores": {"correctness": 0.7924253282122482, "completeness": 0.7424253282122482, "reasoning_quality": 0.7624253282122482, "factuality": 0.9, "robustness": 0.7124253282122482}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7899402625697987, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00040", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.375561+00:00", "seed": 1377, "question": {"question_id": "synthetic_math_v1_1337_00040", "question": "What is 98 + 18?", "answer_key": "116", "source": "synthetic_math_v1", "metadata": {"a": 98, "b": 18, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7999898197246006, "scores": {"correctness": 0.8049872746557506, "completeness": 0.7549872746557506, "reasoning_quality": 0.7749872746557506, "factuality": 0.9, "robustness": 0.7249872746557506}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 98 + 18?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 98 + 18?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 98 + 18?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 98 + 18?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7999898197246006, \"scores\": {\"correctness\": 0.8049872746557506, \"completeness\": 0.7549872746557506, \"reasoning_quality\": 0.7749872746557506, \"factuality\": 0.9, \"robustness\": 0.7249872746557506}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7999898197246006, "scores": {"correctness": 0.8049872746557506, "completeness": 0.7549872746557506, "reasoning_quality": 0.7749872746557506, "factuality": 0.9, "robustness": 0.7249872746557506}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7999898197246006, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00041", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.388314+00:00", "seed": 1378, "question": {"question_id": "synthetic_math_v1_1337_00041", "question": "What is 91 * 169?", "answer_key": "15379", "source": "synthetic_math_v1", "metadata": {"a": 91, "b": 169, "op": "*", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.79485118597993, "scores": {"correctness": 0.7985639824749124, "completeness": 0.7485639824749124, "reasoning_quality": 0.7685639824749124, "factuality": 0.9, "robustness": 0.7185639824749125}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 91 * 169?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 91 * 169?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 91 * 169?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 91 * 169?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.79485118597993, \"scores\": {\"correctness\": 0.7985639824749124, \"completeness\": 0.7485639824749124, \"reasoning_quality\": 0.7685639824749124, \"factuality\": 0.9, \"robustness\": 0.7185639824749125}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.79485118597993, "scores": {"correctness": 0.7985639824749124, "completeness": 0.7485639824749124, "reasoning_quality": 0.7685639824749124, "factuality": 0.9, "robustness": 0.7185639824749125}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.79485118597993, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00042", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.409118+00:00", "seed": 1379, "question": {"question_id": "synthetic_math_v1_1337_00042", "question": "What is 68 + 184?", "answer_key": "252", "source": "synthetic_math_v1", "metadata": {"a": 68, "b": 184, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7920173064711228, "scores": {"correctness": 0.7950216330889034, "completeness": 0.7450216330889033, "reasoning_quality": 0.7650216330889034, "factuality": 0.9, "robustness": 0.7150216330889034}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 68 + 184?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 68 + 184?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 68 + 184?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 68 + 184?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7920173064711228, \"scores\": {\"correctness\": 0.7950216330889034, \"completeness\": 0.7450216330889033, \"reasoning_quality\": 0.7650216330889034, \"factuality\": 0.9, \"robustness\": 0.7150216330889034}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7920173064711228, "scores": {"correctness": 0.7950216330889034, "completeness": 0.7450216330889033, "reasoning_quality": 0.7650216330889034, "factuality": 0.9, "robustness": 0.7150216330889034}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7920173064711228, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00043", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.426403+00:00", "seed": 1380, "question": {"question_id": "synthetic_math_v1_1337_00043", "question": "What is 50 - 35?", "answer_key": "15", "source": "synthetic_math_v1", "metadata": {"a": 50, "b": 35, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7725541966692826, "scores": {"correctness": 0.7706927458366032, "completeness": 0.7206927458366031, "reasoning_quality": 0.7406927458366032, "factuality": 0.9, "robustness": 0.6906927458366032}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 50 - 35?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 50 - 35?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 50 - 35?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 50 - 35?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7725541966692826, \"scores\": {\"correctness\": 0.7706927458366032, \"completeness\": 0.7206927458366031, \"reasoning_quality\": 0.7406927458366032, \"factuality\": 0.9, \"robustness\": 0.6906927458366032}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7725541966692826, "scores": {"correctness": 0.7706927458366032, "completeness": 0.7206927458366031, "reasoning_quality": 0.7406927458366032, "factuality": 0.9, "robustness": 0.6906927458366032}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7725541966692826, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00044", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.439354+00:00", "seed": 1381, "question": {"question_id": "synthetic_math_v1_1337_00044", "question": "What is 101 - 157?", "answer_key": "-56", "source": "synthetic_math_v1", "metadata": {"a": 101, "b": 157, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7797034143565651, "scores": {"correctness": 0.7796292679457064, "completeness": 0.7296292679457064, "reasoning_quality": 0.7496292679457064, "factuality": 0.9, "robustness": 0.6996292679457065}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 101 - 157?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 101 - 157?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 101 - 157?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 101 - 157?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7797034143565651, \"scores\": {\"correctness\": 0.7796292679457064, \"completeness\": 0.7296292679457064, \"reasoning_quality\": 0.7496292679457064, \"factuality\": 0.9, \"robustness\": 0.6996292679457065}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7797034143565651, "scores": {"correctness": 0.7796292679457064, "completeness": 0.7296292679457064, "reasoning_quality": 0.7496292679457064, "factuality": 0.9, "robustness": 0.6996292679457065}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7797034143565651, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00045", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.452015+00:00", "seed": 1382, "question": {"question_id": "synthetic_math_v1_1337_00045", "question": "What is 142 + 65?", "answer_key": "207", "source": "synthetic_math_v1", "metadata": {"a": 142, "b": 65, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7673688753647383, "scores": {"correctness": 0.7642110942059228, "completeness": 0.7142110942059228, "reasoning_quality": 0.7342110942059228, "factuality": 0.9, "robustness": 0.6842110942059229}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 142 + 65?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 142 + 65?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 142 + 65?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 142 + 65?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7673688753647383, \"scores\": {\"correctness\": 0.7642110942059228, \"completeness\": 0.7142110942059228, \"reasoning_quality\": 0.7342110942059228, \"factuality\": 0.9, \"robustness\": 0.6842110942059229}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7673688753647383, "scores": {"correctness": 0.7642110942059228, "completeness": 0.7142110942059228, "reasoning_quality": 0.7342110942059228, "factuality": 0.9, "robustness": 0.6842110942059229}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7673688753647383, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00046", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.471988+00:00", "seed": 1383, "question": {"question_id": "synthetic_math_v1_1337_00046", "question": "What is 57 - 183?", "answer_key": "-126", "source": "synthetic_math_v1", "metadata": {"a": 57, "b": 183, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7677538967621376, "scores": {"correctness": 0.764692370952672, "completeness": 0.7146923709526719, "reasoning_quality": 0.7346923709526719, "factuality": 0.9, "robustness": 0.684692370952672}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 57 - 183?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 57 - 183?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 57 - 183?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 57 - 183?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7677538967621376, \"scores\": {\"correctness\": 0.764692370952672, \"completeness\": 0.7146923709526719, \"reasoning_quality\": 0.7346923709526719, \"factuality\": 0.9, \"robustness\": 0.684692370952672}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7677538967621376, "scores": {"correctness": 0.764692370952672, "completeness": 0.7146923709526719, "reasoning_quality": 0.7346923709526719, "factuality": 0.9, "robustness": 0.684692370952672}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7677538967621376, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00047", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.489232+00:00", "seed": 1384, "question": {"question_id": "synthetic_math_v1_1337_00047", "question": "What is 101 + 160?", "answer_key": "261", "source": "synthetic_math_v1", "metadata": {"a": 101, "b": 160, "op": "+", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7965509791478281, "scores": {"correctness": 0.8006887239347852, "completeness": 0.7506887239347851, "reasoning_quality": 0.7706887239347852, "factuality": 0.9, "robustness": 0.7206887239347852}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 101 + 160?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 101 + 160?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 101 + 160?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 101 + 160?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7965509791478281, \"scores\": {\"correctness\": 0.8006887239347852, \"completeness\": 0.7506887239347851, \"reasoning_quality\": 0.7706887239347852, \"factuality\": 0.9, \"robustness\": 0.7206887239347852}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7965509791478281, "scores": {"correctness": 0.8006887239347852, "completeness": 0.7506887239347851, "reasoning_quality": 0.7706887239347852, "factuality": 0.9, "robustness": 0.7206887239347852}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7965509791478281, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00048", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.501750+00:00", "seed": 1385, "question": {"question_id": "synthetic_math_v1_1337_00048", "question": "What is 196 - 160?", "answer_key": "36", "source": "synthetic_math_v1", "metadata": {"a": 196, "b": 160, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.7717129148397743, "scores": {"correctness": 0.7696411435497179, "completeness": 0.7196411435497179, "reasoning_quality": 0.7396411435497179, "factuality": 0.9, "robustness": 0.689641143549718}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 196 - 160?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 196 - 160?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 196 - 160?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 196 - 160?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.7717129148397743, \"scores\": {\"correctness\": 0.7696411435497179, \"completeness\": 0.7196411435497179, \"reasoning_quality\": 0.7396411435497179, \"factuality\": 0.9, \"robustness\": 0.689641143549718}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.7717129148397743, "scores": {"correctness": 0.7696411435497179, "completeness": 0.7196411435497179, "reasoning_quality": 0.7396411435497179, "factuality": 0.9, "robustness": 0.689641143549718}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.7717129148397743, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
{"schema_version": "case_v1", "case_id": "exp_20251216T211331Z_1ecb770b_case_00049", "experiment_id": "exp_20251216T211331Z_1ecb770b", "created_at": "2025-12-16T21:13:32.515750+00:00", "seed": 1386, "question": {"question_id": "synthetic_math_v1_1337_00049", "question": "What is 41 - 184?", "answer_key": "-143", "source": "synthetic_math_v1", "metadata": {"a": 41, "b": 184, "op": "-", "difficulty": "mixed"}}, "rounds": [{"round_idx": 0, "candidate": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}, "prosecutor": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}, "defense": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}, "judge": {"verdict": "accept", "confidence": 0.775170261063957, "scores": {"correctness": 0.7739628263299463, "completeness": 0.7239628263299462, "reasoning_quality": 0.7439628263299463, "factuality": 0.9, "robustness": 0.6939628263299463}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}, "llm_calls": [{"role": "candidate", "model_id": "mock-candidate-v1", "prompt": "You are the Candidate Model. Answer the question.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"final_answer\": \"string\",\n  \"reasoning_summary\": [\"string\", \"...\"],\n  \"assumptions\": [\"string\", \"...\"],\n  \"citations\": [\"string\", \"...\"],\n  \"uncertainty\": \"string|null\"\n}\n\nRules:\n- Put the user-facing answer in \"final_answer\".\n- \"reasoning_summary\" is a concise bullet list. Do NOT include hidden chain-of-thought.\n- Be explicit about assumptions.\n\nINPUT:\n{\n  \"question\": \"What is 41 - 184?\",\n  \"prior_rounds\": [],\n  \"instruction\": \"Provide the best answer.\"\n}\n\n", "response_text": "{\"final_answer\": \"Answer: (mock) See reasoning summary.\", \"reasoning_summary\": [\"Parse the question and identify the target quantity.\", \"Apply the relevant rule/calculation.\", \"Return the result with units/formatting.\"], \"assumptions\": [\"Question is self-contained.\"], \"citations\": [], \"uncertainty\": null}", "parsed_json": {"final_answer": "Answer: (mock) See reasoning summary.", "reasoning_summary": ["Parse the question and identify the target quantity.", "Apply the relevant rule/calculation.", "Return the result with units/formatting."], "assumptions": ["Question is self-contained."], "citations": [], "uncertainty": null}}, {"role": "prosecutor", "model_id": "mock-prosecutor-v1", "prompt": "You are the Prosecutor. Your job is to aggressively challenge the candidate answer.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"objections\": [\"string\", \"...\"],\n  \"counterexamples\": [\"string\", \"...\"],\n  \"missing_assumptions\": [\"string\", \"...\"],\n  \"factuality_flags\": [\"string\", \"...\"],\n  \"targeted_questions\": [\"string\", \"...\"]\n}\n\nRules:\n- Be adversarial, specific, and testable.\n- Attack logic, assumptions, edge cases, and factuality.\n- Prefer concrete counterexamples and verification questions.\n\nINPUT:\n{\n  \"question\": \"What is 41 - 184?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  }\n}\n\n", "response_text": "{\"objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"counterexamples\": [\"If the question intends a different unit or definition, the result changes.\"], \"missing_assumptions\": [\"Define any implied constraints (integer-only? rounding?).\"], \"factuality_flags\": [], \"targeted_questions\": [\"What assumptions are required for the calculation to be valid?\"]}", "parsed_json": {"objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "counterexamples": ["If the question intends a different unit or definition, the result changes."], "missing_assumptions": ["Define any implied constraints (integer-only? rounding?)."], "factuality_flags": [], "targeted_questions": ["What assumptions are required for the calculation to be valid?"]}}, {"role": "defense", "model_id": "mock-defense-v1", "prompt": "You are the Defense Attorney. Defend the candidate answer and rebut the prosecutor.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"rebuttals\": [\"string\", \"...\"],\n  \"corrections\": [\"string\", \"...\"],\n  \"strengthened_answer\": \"string|null\",\n  \"resolved_objections\": [\"string\", \"...\"],\n  \"unresolved_objections\": [\"string\", \"...\"]\n}\n\nRules:\n- Concede real errors; propose corrections.\n- \"strengthened_answer\" should be a revised final answer only if necessary.\n- Map objections into resolved vs unresolved.\n\nINPUT:\n{\n  \"question\": \"What is 41 - 184?\",\n  \"candidate_answer\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  }\n}\n\n", "response_text": "{\"rebuttals\": [\"The method matches the most direct reading of the problem.\", \"Assumptions can be made explicit without changing the result.\"], \"corrections\": [], \"strengthened_answer\": null, \"resolved_objections\": [\"The answer does not justify why the chosen method applies.\", \"Edge cases and alternative interpretations are not addressed.\"], \"unresolved_objections\": []}", "parsed_json": {"rebuttals": ["The method matches the most direct reading of the problem.", "Assumptions can be made explicit without changing the result."], "corrections": [], "strengthened_answer": null, "resolved_objections": ["The answer does not justify why the chosen method applies.", "Edge cases and alternative interpretations are not addressed."], "unresolved_objections": []}}, {"role": "judge", "model_id": "mock-judge-v1", "prompt": "You are the Judge. Evaluate both sides and issue a final ruling with explicit criteria.\n\nReturn ONLY a single JSON object with this schema:\n{\n  \"verdict\": \"accept|revise|reject\",\n  \"confidence\": 0.0,\n  \"scores\": {\n    \"correctness\": 0.0,\n    \"completeness\": 0.0,\n    \"reasoning_quality\": 0.0,\n    \"factuality\": 0.0,\n    \"robustness\": 0.0\n  },\n  \"justification\": [\"string\", \"...\"],\n  \"key_failures\": [\"string\", \"...\"],\n  \"required_fixes\": [\"string\", \"...\"],\n  \"consistency_checks\": {\"check_name\": true},\n  \"tags\": [\"string\", \"...\"]\n}\n\nRubric:\n- correctness: is the final answer correct?\n- completeness: does it address the full question?\n- reasoning_quality: clarity and logical soundness (no hidden chain-of-thought required).\n- factuality: avoids unverifiable claims or clearly marks uncertainty.\n- robustness: handles edge cases and objections.\n\nINPUT:\n{\n  \"question\": \"What is 41 - 184?\",\n  \"candidate_answer\": \"Answer: (mock) See reasoning summary.\",\n  \"candidate_structured\": {\n    \"final_answer\": \"Answer: (mock) See reasoning summary.\",\n    \"reasoning_summary\": [\n      \"Parse the question and identify the target quantity.\",\n      \"Apply the relevant rule/calculation.\",\n      \"Return the result with units/formatting.\"\n    ],\n    \"assumptions\": [\n      \"Question is self-contained.\"\n    ],\n    \"citations\": [],\n    \"uncertainty\": null\n  },\n  \"prosecutor\": {\n    \"objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"counterexamples\": [\n      \"If the question intends a different unit or definition, the result changes.\"\n    ],\n    \"missing_assumptions\": [\n      \"Define any implied constraints (integer-only? rounding?).\"\n    ],\n    \"factuality_flags\": [],\n    \"targeted_questions\": [\n      \"What assumptions are required for the calculation to be valid?\"\n    ]\n  },\n  \"defense\": {\n    \"rebuttals\": [\n      \"The method matches the most direct reading of the problem.\",\n      \"Assumptions can be made explicit without changing the result.\"\n    ],\n    \"corrections\": [],\n    \"strengthened_answer\": null,\n    \"resolved_objections\": [\n      \"The answer does not justify why the chosen method applies.\",\n      \"Edge cases and alternative interpretations are not addressed.\"\n    ],\n    \"unresolved_objections\": []\n  },\n  \"rubric\": {\n    \"accept_threshold\": 0.75,\n    \"confidence_threshold\": 0.75,\n    \"require_no_unresolved_objections\": true\n  }\n}\n\n", "response_text": "{\"verdict\": \"accept\", \"confidence\": 0.775170261063957, \"scores\": {\"correctness\": 0.7739628263299463, \"completeness\": 0.7239628263299462, \"reasoning_quality\": 0.7439628263299463, \"factuality\": 0.9, \"robustness\": 0.6939628263299463}, \"justification\": [\"Defense addressed the prosecutor's objections.\", \"Answer is plausible and internally consistent for the given question.\"], \"key_failures\": [], \"required_fixes\": [], \"consistency_checks\": {\"no_unresolved_objections\": true}, \"tags\": [\"mock\", \"demo\"]}", "parsed_json": {"verdict": "accept", "confidence": 0.775170261063957, "scores": {"correctness": 0.7739628263299463, "completeness": 0.7239628263299462, "reasoning_quality": 0.7439628263299463, "factuality": 0.9, "robustness": 0.6939628263299463}, "justification": ["Defense addressed the prosecutor's objections.", "Answer is plausible and internally consistent for the given question."], "key_failures": [], "required_fixes": [], "consistency_checks": {"no_unresolved_objections": true}, "tags": ["mock", "demo"]}}]}], "final_answer": "Answer: (mock) See reasoning summary.", "final_verdict": "accept", "final_overall_score": 0.775170261063957, "metadata": {"config_snapshot": {"experiment": {"seed": 1337, "max_rounds": 2, "n_questions": 50, "output_dir": "datasets/raw", "runs_dir": "runs"}, "models": {"provider": "mock", "candidate_id": "mock-candidate-v1", "prosecutor_id": "mock-prosecutor-v1", "defense_id": "mock-defense-v1", "judge_id": "mock-judge-v1"}, "question_source": {"type": "synthetic_math_v1", "difficulty": "mixed"}, "judge": {"accept_threshold": 0.75, "confidence_threshold": 0.75, "require_no_unresolved_objections": true}, "vector_store": {"embedder": "hashing_v1", "dim": 1024, "chunk_chars": 1400, "chunk_overlap": 120}}}}
